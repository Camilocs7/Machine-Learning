PredicciÃ³n de Series Temporales con LSTM + Mecanismo de AtenciÃ³n
Proyecto â€” Modelos LSTM con AtenciÃ³n aplicados a datos de precios

Este repositorio contiene el cÃ³digo, datos y notebooks utilizados para entrenar y evaluar un modelo de LSTM con mecanismo de AtenciÃ³n para la predicciÃ³n de series temporales de precios. El foco principal del proyecto es mejorar la capacidad del modelo para aprender dependencias a largo plazo incorporando un mÃ³dulo de atenciÃ³n personalizado en TensorFlow/Keras.

ğŸ§  DescripciÃ³n del Proyecto

El objetivo es predecir el valor futuro de un producto usando su historial de precios diarios. Se implementa:

NormalizaciÃ³n MinMaxScaler

GeneraciÃ³n de ventanas temporales

Modelo LSTM clÃ¡sico

Modelo LSTM Bidireccional

Capa de AtenciÃ³n personalizada (AttentionLayer)

Entrenamiento con EarlyStopping

EvaluaciÃ³n mediante MAE y RMSE

Guardado automÃ¡tico de los mejores modelos por producto

EjecuciÃ³n en bucle sobre mÃºltiples IDs de productos

El pipeline estÃ¡ diseÃ±ado para procesar mÃºltiples series temporales y generar un modelo Ã³ptimo para cada una.

ğŸ“‚ Estructura del Repositorio
ğŸ“ DEEP/
â”‚â”€â”€ codigo_completo.ipynb
â”‚â”€â”€ codigo_completo_LSTM_ATTENTION.ipynb   â† Notebook principal del proyecto
â”‚â”€â”€ lstm_prueba3/                           â† Modelos entrenados (uno por producto)
â”‚â”€â”€ mapeo_productos.csv
â”‚â”€â”€ mapeo_productos2.csv
â”‚â”€â”€ mis_datos_finales.csv
â”‚â”€â”€ precio_2023.csv
â”‚â”€â”€ precio_2024.csv
â”‚â”€â”€ precio_2025.csv
â”‚â”€â”€ precios_combinados2.csv
â”‚â”€â”€ precios_estandarizados.csv
â”‚â”€â”€ precios_estandarizados2.csv
â”‚â”€â”€ precios_final_features2.csv
â”‚â”€â”€ requirements.txt
â”‚â”€â”€ README.md   â† (este archivo)



ğŸ”§ OPCIÃ“N A â€” Ejecutar SIN Docker (entorno local)
1. Clonar el repositorio
git clone git@github.com:Camilocs7/Machine-Learning.git
cd Machine-Learning

2. Crear entorno virtual
python3 -m venv venv
source venv/bin/activate

3. Instalar dependencias
pip install -r requirements.txt

4. Verificar TensorFlow
import tensorflow as tf
tf.__version__





ğŸ³ OPCIÃ“N B â€” Ejecutar CON Docker (recomendado)
1. Construir la imagen
docker build -t lstm-attention .

2. Ejecutar el contenedor con JupyterLab
docker-compose up


Esto levanta JupyterLab en:
ğŸ‘‰ http://localhost:8888

Sin token, todo listo para usar.




âš™ï¸ TecnologÃ­as Utilizadas

Python 3.x

TensorFlow / Keras

NumPy

Pandas

Scikit-learn

Matplotlib

Joblib

ğŸ—ï¸ Arquitectura del Modelo

El modelo central estÃ¡ compuesto por:

Capa de entrada

LSTM o BiLSTM

Capa de AtenciÃ³n personalizada, que:

Calcula pesos de importancia para cada timestamp

Genera un contexto ponderado

Densas finales para regresiÃ³n

ğŸ” Diagrama simplificado
Input â†’ LSTM/BiLSTM â†’ AttentionLayer â†’ Dense â†’ Output

ğŸ“Š MÃ©tricas de EvaluaciÃ³n

El modelo evalÃºa:

MAE (Mean Absolute Error)

RMSE (Root Mean Squared Error)

AutomÃ¡ticamente guarda el modelo con menor pÃ©rdida de validaciÃ³n.

ğŸš€ CÃ³mo Ejecutar el Proyecto
1. Instalar dependencias
pip install -r requirements.txt

2. Ejecutar el notebook principal

Abre en Jupyter o VS Code:

codigo_completo_LSTM_ATTENTION.ipynb

3. Entrenar el modelo para todos los productos

El notebook incluye un loop como este:

for product_id in unique_ids:
    train_lstm_attention(product_id)

ğŸ“ Datos

Debido al tamaÃ±o, los datasets no estÃ¡n incluidos en este repositorio.  
Puedes descargarlos desde Kaggle:

https://www.kaggle.com/datasets/paulohernandezt/price-product-chile/data

El pipeline une y limpia estos datos para generar series de entrenamiento.

ğŸ† Resultados

Se genera un modelo por producto

Se obtiene MAE y RMSE por cada serie

Los mejores modelos quedan guardados en:

/lstm_prueba3/models/prod_X/best_model.h5


El proyecto permite comparar rendimiento entre LSTM clÃ¡sico y LSTM con AtenciÃ³n, mostrando mejoras en series con patrones complejos.

ğŸ“Œ Autor

Camilo Cerda Sarabia
Proyecto aplicado a series temporales.# Machine-Learning
